---
title: "Intro to DS - Logit Regression"
author: ""
# date: "today"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
```

# HW Assignment - Logit Regression

We have the historic Titanic dataset to study here. The version presented has these variables: 

* `survival`: Survival,	0 = No, 1 = Yes
* `pclass`: Ticket class, 1 = 1st, 2 = 2nd, 3 = 3rd
* `sex`: Gender / Sex
* `age`: Age in years
* `sibsp`: # of siblings / spouses on the Titanic
* `parch`: # of parents / children on the Titanic
* `ticket`: Ticket number (for superstitious ones)
* `fare`: Passenger fare
* `embarked`: Port of Embarkment	C: Cherbourg, Q: Queenstown, S: Southampton

The questions listed here are the basic guidelines, not the only goal, in this homework. For example, after you load the dataframe, even though the question does not ask you to look at the structure of the dataframe, you most likely should. You are given less and less “specific to-dos” in the homework, as you are getting more familiar with the data analytic process. Calculate and figure out the necessary info needed in the analysis, even though the questions might not ask for them explicitly. When you look at your own work, you should find it convincing, answering the questions and technically sound.  


## Titanic Tragedy Dataset  

### Question 1

**Import the dataset into R**  
Import the dataset into R, and call it titanic_orig, and explore it little to get the overall picture of the dataset. Eventually we would like to see what affected survival in the tragedy.  
```{r, results='asis'}
titanic_orig <- read.csv('Titanic.csv', header=T,
                         colClasses = c(sex='factor', embarked='factor', 
                                        pclass='factor', survived='factor'),
                         fill=T, strip.white=T,
                         blank.lines.skip=T
                         )
rmarkdown::paged_table(titanic_orig)
```


### Question 2 
**Age**  
One of the main factors we will try is Age. How many missing values are there for the variable `age`? If not too many, we should just clean those up and subset those out.  

There are about `r summary(titanic_orig$age)[['NA\'s']]` missing values in age. 
```{r clean_subset, results='asis'}
titanic.cleaned.age <- outlierKD2(titanic_orig, var=age, rm=T, histogram=F) # Since you said "clean"
missing.age.bool <- is.na(titanic.cleaned.age$age)
filter.bool <- as.logical(1 - missing.age.bool)
titanic.cleaned.age <- titanic.cleaned.age[filter.bool,]
xkablesummary(titanic.cleaned.age)
```

### Question 3  
**More clean up**  
While we are cleaning up the data, if we were to use sibsp and parch in our analysis, even though they are legitimately ratio level variables, we might not expect doubling the number of siblings necessarily double the effects on survival. For this reason, we should change these two variables to factor levels. Also change the other ones that you find imported as the wrong data type.  

Other variables such as `survived`, `pclass`, `sex`, `embarked` have already been converted into factor variables while importing the dataset. Hence, I will convert `sibsp` and `parch` here.  

```{r, results='asis'}
titanic.cleaned.sibparc <- titanic.cleaned.age
titanic.cleaned.sibparc$sibsp <- as.factor(titanic.cleaned.sibparc$sibsp)
titanic.cleaned.sibparc$parch <- as.factor(titanic.cleaned.sibparc$parch)
# Since it appears that we are no longer involved in cleaning, I will assign a new var
titanic.cleaned <- titanic.cleaned.sibparc
rmarkdown::paged_table(titanic.cleaned)
```


## Pre-logistic Regression

### Question 4  
**Survival and age**  
Before using our newly learned technique with logistic regression, let’s go old school, and use some prior knowledge to try find an answer. Does the data support that `age` very much affects `survival`?
```{r age.ttest, results='markup'}
survived.age <- titanic.cleaned[titanic.cleaned$survived==1,]$age
not.survived.age <- titanic.cleaned[titanic.cleaned$survived==0,]$age

age_survival <- t.test(survived.age, not.survived.age)
age_survival

```

A `t.test` shows the variable `age` does not appear to have any effect on variable `survived` as the `p.value` is `r round(age_survival$p.value, 4)`. In other words, we fail to reject the Null hypothesis $H_{0}$ as any difference in age between the two subgroups survived and not survived is mere random.  

### Question 5  
**Survival and gender**  
Similarly, does the data support `sex` has an effect on `survival`? 
```{r sex.chisq, results='markup'}
sex.survival.cont <- table(titanic.cleaned$survived, titanic.cleaned$sex)
sex.survival <- chisq.test(sex.survival.cont)
sex.survival
```

Since `sex` and `survived` are categorical variables, I performed a $\chi^2$ test that produced a `p.value` of `r round(sex.survival$p.value, 4)`, which confirms that being a man or a woman does have an influence on the survival.  

### Question 6   
**Survival and pclass**  
Another big question is, does the data support Ticket class `pclass` has an effect on `survival`? 
```{r pclass.chisq, results='markup'}
pclass.survival.cont <- table(titanic.cleaned$survived, titanic.cleaned$pclass)
pclass.survival <- chisq.test(pclass.survival.cont)
pclass.survival
```

It appears from the $\chi^2$ test that `pclass` does have an effect on the var `survived` as the `p.value` is `r round(pclass.survival$p.value, 4)`. Perhaps first class passengers get privileged access to safety boats.  

## Logistic Regression

### Question 7   
**Survival and age + pclass**  
Now let us build a logit model with age+pclass as predictors, and analyze the results. Remember to do all the model evaluation steps. Is the model a good one?
```{r base.model, results='markup'}

model.base <- glm(survived~age+pclass, data=titanic.cleaned, family=binomial(link='logit'))
model.base
summary(model.base)
x2 <- model.base$null.deviance - model.base$deviance
df <- 2
base.model.p.value <- pchisq(x2, df, lower.tail=F)

```
```{r base.model.eval, results='markup'}
get_cm <- function(predictions, model, co)
{
  # pred.list <- round(predictions) # for now
  pred.list <- predictions
  pred.list[predictions <= co] <- 1
  pred.list[predictions > co] <- 2
  cm <- matrix(0, nrow=2, ncol=2)
  survived <- as.numeric(titanic.cleaned$survived)
  for(i in 1:length(pred.list))
  {
    actual <- survived[i]
    pred <- pred.list[i]
    cm[pred, actual] <- cm[pred, actual] + 1
  }
return(cm)
}

get_evalmetrics <- function(cm, model, n_preds)
{
  precision <- cm[1, 1]/(cm[1, 1] + cm[1, 2])
  recall <- cm[1, 1]/(cm[1, 1] + cm[2, 1])
  sensitivity <- recall
  specificity <- cm[2, 2]/(cm[2, 2] + cm[1, 2])
  f1 <- 2 * ((precision * recall)/(precision + recall))
  colnames(cm) <- c('Act.Pos', 'Act.Neg')
  mcfadden <- 1 - model$deviance/model$null.deviance
  accuracy <- (cm[1, 1] + cm[2, 2])/n_preds
  metrics <- c(precision, recall, sensitivity, specificity, f1, mcfadden, accuracy)
  return(metrics)
}
```


```{r base.model.cm, results='markup'}
base.pred <- predict.glm(model.base, newdata=titanic.cleaned, type='response')
base.cm <- NULL
co_threshs <- seq(0.3, 0.7, 0.05)
model.base.metrics <- data.frame(matrix(0, nrow=length(co_threshs), ncol=8))
colnames(model.base.metrics) <- c('Cutoff', 'Precision', 'Recall', 'Sensitivity', 'Specificity', 'F1', 'McFadden', 'Accuracy')
idx = 1
for(co in co_threshs)
{
  tmp.cm <- get_cm(base.pred, model.base, co)
  if(co == 0.5)
  {
    base.cm <- tmp.cm
  }
  tmp.metrics <- get_evalmetrics(tmp.cm, model.base, length(base.pred))
  tmp.metrics <- c(co, tmp.metrics)
  model.base.metrics[idx,] <- tmp.metrics
  idx <- idx + 1
}
rmarkdown::paged_table(model.base.metrics)
colnames(base.cm) <- c('Actually Pos', 'Actually Neg')
```

**Confusion Matrix for cutoff 0.5**  
```{r, results='markup'}
base.cm
```

Looking at the `Specificity`, `McFadden` and the `F1` scores, I would not say it is a good model.  

```{r}
library(pROC)
tmp.titanic <- titanic.cleaned
tmp.titanic$prob <- base.pred
h <- roc(survived~prob, data=tmp.titanic)
plot(h)
```

### Question 8  
**More features**  
Can we improve the model? Let us also throw in `sex` as a predictor. How’s the model now?
```{r model2, results='markup'}
model2 <- glm(survived~age+pclass+sex, data=titanic.cleaned, family=binomial(link='logit'))
model2
summary(model2)
```

```{r model2.eval, results='markup'}
model2.pred <- predict.glm(model2, newdata=titanic.cleaned, type='response')
model2.metrics <- data.frame(matrix(0, nrow=length(co_threshs), ncol=8))
colnames(model2.metrics) <- c('Cutoff', 'Precision', 'Recall', 'Sensitivity', 'Specificity', 'F1', 'McFadden', 'Accuracy')
idx = 1
for(co in co_threshs)
{
  tmp.cm <- get_cm(model2.pred, model2, co)
  if(co == 0.5)
  {
    model2.cm <- tmp.cm
  }
  tmp.metrics <- get_evalmetrics(tmp.cm, model2, length(model2.pred))
  tmp.metrics <- c(co, tmp.metrics)
  model2.metrics[idx,] <- tmp.metrics
  idx <- idx + 1
}
rmarkdown::paged_table(model2.metrics)
colnames(model2.cm) <- c('Actually Pos', 'Actually Neg')

```

**Confusion Matrix for cutoff 0.5**  
```{r, results='markup'}
model2.cm
```


```{r}
library(pROC)
tmp.titanic$prob <- model2.pred
h <- roc(survived~prob, data=tmp.titanic)
plot(h)
```

Compared to the previous models, almost all evaluation metrics including AIC have improved. Also the ROC curve appears good now. Hence, the model appears to be better than the previous model. P.S: Somehow I have always, in the past, been biased to look only at the F1 score compared to Accuracy, but carefully looking at the accuracy now it appears increasingly useful than F1. F1 might be a harmonic mean of precision and recall, but Accuracy gives an overall good balance between specificity and sensitivity. If you observe the values for the cutoff 0.65, the $F1$ score is $0.844$, and although has high sensitivity (recall of positive class), the specificity (the recall rate of negative class) is low. In my opinion, correctly predicting positive class carries the same priority as predicting negative class unless a preconceived bias from expert domain is involved. Under this case, an accuracy of $80.6\%$ for cutoff $0.45$ appears as a well balanced measure between Specificity and Sensitivity, after all that's the formula.  

### Question 9  
**Sample Predictions**  
According to the last model, what is the chance of survival for a female, age 10, second class passenger? And a male, age 20, first class passenger?
```{r}
tmp.df <- titanic.cleaned[1:2, c('sex', 'age', 'pclass')]
tmp.df[1,] <- c('female', 10, 2)
tmp.df[2,] <- c('male', 20, 1)
tmp.df$age <- as.numeric(tmp.df$age)
sample.pred <- predict.glm(model2, newdata=tmp.df, type='response')
```

For the first case when it is a 10 years old girl, who bought a second class ticket, her chances of surviving would be `r sample.pred[1]*100`$\%$ as per the previous model, whereas in the case of 20 years old male, who bought a first class ticket, his chances of surviving would be `r sample.pred[2]*100`$\%$  

## Interpretation  

### Question 10  
*Summary*  
With all the results you obtained above, how would you present a high-level summary of the findings? Are the results surprising or expected? You might need to dig a little deeper than just the numbers, the test results/p-values, and the model statistics. This is a question about who we are, … in the face of death. 

My understanding from this finding, from a statistical perspective, would be that `sex` is apparently the influencing factor of `survival`. From the perspective you have portrayed, the reason I could think of would be being a girl often involves having more sympathy on someone being left behind compared to a man, who is regardless of his age, is expected to be more audacious and sail against the storm. In simple words, there is a gender bias.  

```{r last.eval, include=F}
tmp.df3 <- titanic.cleaned[1:2, c('sex', 'age', 'pclass')]
tmp.df3[1,] <- c('male', 5, 1)
tmp.df3[2,] <- c('female', 30, 2)
tmp.df3$age <- as.numeric(tmp.df3$age)
sample.pred3 <- predict.glm(model2, newdata=tmp.df3, type='response')
```

A boy, who is 5 years old and holds a first class ticket has a relatively low chance of `r sample.pred3[1]*100` $\%$ surviving compared to a woman, who is 30 years old and holds a second class ticket. The woman has about `r sample.pred3[2]*100` $\%$ of surviving. This clearly shows the gender bias I mentioned.  